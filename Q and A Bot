{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5386151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.11.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: openai in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.59.7)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.48.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: streamlit in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.41.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.44.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfplumber) (9.2.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (37.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (2.10.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (4.24.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (6.5.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.11.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (3.10.14)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (3.5.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.9.1)\n",
      "Requirement already satisfied: fastapi<1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.3.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.12.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.16.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.5)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from fastapi<1.0->gradio) (0.41.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.8.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install pdfplumber pandas openai faiss-cpu transformers sentence-transformers streamlit gradio langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7444f6",
   "metadata": {},
   "source": [
    "EXTRACT P&L DATA FROM PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2050f980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P&L data extracted and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_path = \"Sample Financial Statement.pdf\"\n",
    "\n",
    "# Extract P&L data\n",
    "try:\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Select the page containing P&L data (e.g., page 2)\n",
    "        page = pdf.pages[1]  # Adjust the page index as needed\n",
    "        text = page.extract_text()\n",
    "\n",
    "    # Clean the text for encoding issues\n",
    "    cleaned_text = text.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "\n",
    "    # Save the cleaned text to a file\n",
    "    with open(\"extracted_pnl_cleaned.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text)\n",
    "\n",
    "    print(\"P&L data extracted and saved successfully!\")\n",
    "\n",
    "except UnicodeEncodeError as e:\n",
    "    print(f\"Encoding error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4ec01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DataFrame:\n",
      "       Column_0          Column_1 Column_2   Column_3 Column_4 Column_5  \\\n",
      "0     Condensed      Consolidated  Balance     Sheets       as       at   \n",
      "1     Property,             plant      and  equipment      2.2   12,370   \n",
      "2  Right-of-use            assets     2.19      6,552    6,882     None   \n",
      "3       Capital  work-in-progress      293        288     None     None   \n",
      "4      Goodwill               2.3    7,303      7,248     None     None   \n",
      "\n",
      "  Column_6 Column_7 Column_8 Column_9 Column_10 Column_11 Column_12 Column_13  \n",
      "0     Note      No.    March      31,      2024     March       31,      2023  \n",
      "1   13,346     None     None     None      None      None      None      None  \n",
      "2     None     None     None     None      None      None      None      None  \n",
      "3     None     None     None     None      None      None      None      None  \n",
      "4     None     None     None     None      None      None      None      None  \n",
      "Raw structured data saved to raw_pnl_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned text file\n",
    "file_path = \"extracted_pnl_cleaned.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    cleaned_text = f.read()\n",
    "\n",
    "# Split the text into lines\n",
    "lines = cleaned_text.splitlines()\n",
    "\n",
    "# Process each line to filter meaningful financial data\n",
    "data = []\n",
    "for line in lines:\n",
    "    # Check if the line contains financial data (adjust filter criteria as needed)\n",
    "    if \"₹\" in line or any(char.isdigit() for char in line):  # Properly close the condition\n",
    "        parts = line.split()  # Split line into parts based on spaces\n",
    "        data.append(parts)\n",
    "\n",
    "# Find the maximum number of columns in the data\n",
    "max_columns = max(len(row) for row in data)\n",
    "\n",
    "# Create a DataFrame with dynamic column handling\n",
    "df = pd.DataFrame(data, columns=[f\"Column_{i}\" for i in range(max_columns)])\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(\"Parsed DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV for further processing\n",
    "df.to_csv(\"raw_pnl_data.csv\", index=False)\n",
    "print(\"Raw structured data saved to raw_pnl_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3faaa18",
   "metadata": {},
   "source": [
    "CLEAN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24497c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n",
      "           Category  2024 (₹ crore)  2023 (₹ crore)\n",
      "1         Property,             NaN    2.212370e+00\n",
      "2      Right-of-use    2.196552e+00    6.882000e+03\n",
      "3           Capital    2.932880e+05             NaN\n",
      "4          Goodwill    7.303725e+07             NaN\n",
      "5             Other             NaN    1.749000e+03\n",
      "6       Investments    1.170813e+09             NaN\n",
      "7             Loans    3.439000e+03             NaN\n",
      "8             Other             NaN    3.105280e+07\n",
      "9          Deferred             NaN    4.541245e+06\n",
      "10           Income             NaN    3.045645e+07\n",
      "11            Other             NaN    2.121232e+07\n",
      "12            Total             NaN    5.493500e+04\n",
      "13      Investments    1.291569e+08             NaN\n",
      "14            Trade    2.730193e+00    2.542400e+04\n",
      "15             Cash             NaN    2.814786e+00\n",
      "16            Loans    2.482890e+05             NaN\n",
      "17            Other             NaN    1.208512e+09\n",
      "18           Income             NaN    6.397600e+04\n",
      "19            Other             NaN    1.280814e+09\n",
      "20            Total             NaN    7.088100e+04\n",
      "21            Total    1.378141e+11             NaN\n",
      "22           Equity             NaN    2.071207e+07\n",
      "23            Other    8.604573e+09             NaN\n",
      "25  Non-controlling    3.453880e+05             NaN\n",
      "26            Total    8.846176e+09             NaN\n",
      "27            Lease    2.196400e+00    7.057000e+03\n",
      "28            Other             NaN    2.130206e+07\n",
      "29         Deferred             NaN    1.794122e+07\n",
      "30            Other             NaN    2.355000e+05\n",
      "31            Total             NaN    1.083500e+04\n",
      "32            Lease    2.191959e+00    1.242000e+03\n",
      "33            Trade    3.956386e+07             NaN\n",
      "34            Other             NaN    1.695919e+09\n",
      "35            Other             NaN    1.053911e+09\n",
      "36       Provisions    1.796131e+07             NaN\n",
      "37           Income             NaN    3.585338e+07\n",
      "38            Total             NaN    3.918600e+04\n",
      "39            Total             NaN    1.378141e+11\n",
      "Cleaned structured data saved to cleaned_pnl_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "df = pd.read_csv(\"raw_pnl_data.csv\")\n",
    "\n",
    "# Drop rows with missing values in important columns (adjust based on your data)\n",
    "df = df.dropna(how=\"all\", subset=[\"Column_1\", \"Column_2\"])\n",
    "\n",
    "# Combine related columns into meaningful categories\n",
    "df[\"Category\"] = df[\"Column_0\"]  # Assume Column_0 holds the category names\n",
    "df[\"2024 (₹ crore)\"] = df[\"Column_2\"].fillna(\"\") + df[\"Column_3\"].fillna(\"\")\n",
    "df[\"2023 (₹ crore)\"] = df[\"Column_4\"].fillna(\"\") + df[\"Column_5\"].fillna(\"\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df[[\"Category\", \"2024 (₹ crore)\", \"2023 (₹ crore)\"]]\n",
    "\n",
    "# Clean numerical columns (remove commas and convert to numbers)\n",
    "df[\"2024 (₹ crore)\"] = pd.to_numeric(df[\"2024 (₹ crore)\"].str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "df[\"2023 (₹ crore)\"] = pd.to_numeric(df[\"2023 (₹ crore)\"].str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "\n",
    "# Drop rows where both numerical columns are empty\n",
    "df = df.dropna(subset=[\"2024 (₹ crore)\", \"2023 (₹ crore)\"], how=\"all\")\n",
    "\n",
    "# Preview the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Save the cleaned data for further processing\n",
    "df.to_csv(\"cleaned_pnl_data.csv\", index=False)\n",
    "print(\"Cleaned structured data saved to cleaned_pnl_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b263f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create embeddings for each row in the DataFrame\n",
    "df[\"Embeddings\"] = df[\"Category\"].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Save embeddings for retrieval\n",
    "import pickle\n",
    "with open(\"embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df.to_dict(orient=\"records\"), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb5bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the total revenue for 2024?\n",
      "Answer based on P&L data: Income from the sale of the stadium to the NFL is $1.5 billion. The NFL is expected to pay $1.5 billion in taxes on the sale of the stadium.\n",
      "The NFL is expected to pay $1.5 billion in taxes on the sale of the stadium. The NFL is expected to pay $1.5 billion in taxes on the sale of the stadium to the NFL.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load embeddings\n",
    "with open(\"embeddings.pkl\", \"rb\") as f:\n",
    "    records = pickle.load(f)\n",
    "\n",
    "# Extract embeddings and categories\n",
    "categories = [record[\"Category\"] for record in records]\n",
    "embeddings = np.array([record[\"Embeddings\"] for record in records], dtype=\"float32\")\n",
    "\n",
    "# Create FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "# Query the RAG model\n",
    "def query_rag_model(question, k=1):\n",
    "    query_embedding = model.encode(question).astype(\"float32\")\n",
    "    distances, indices = index.search(np.array([query_embedding]), k)\n",
    "    results = [categories[i] for i in indices[0]]\n",
    "    \n",
    "    # Generate response using GPT\n",
    "    from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "    \n",
    "    input_text = f\"Question: {question}\\nAnswer based on P&L data: {results[0]}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    output = gpt_model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Test the model\n",
    "print(query_rag_model(\"What is the total revenue for 2024?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9905e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 12:01:30.283 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.189 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-01-17 12:01:31.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.196 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.203 Session state does not function when running a script without `streamlit run`\n",
      "2025-01-17 12:01:31.203 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-17 12:01:31.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Streamlit app\n",
    "st.title(\"P&L QA Bot\")\n",
    "uploaded_file = st.file_uploader(\"Upload a financial statement PDF\", type=[\"pdf\"])\n",
    "question = st.text_input(\"Ask a question about the P&L data:\")\n",
    "\n",
    "if uploaded_file and question:\n",
    "    with pdfplumber.open(uploaded_file) as pdf:\n",
    "        text = pdf.pages[1].extract_text()\n",
    "    response = query_rag_model(question)\n",
    "    st.write(f\"Answer: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d99dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Gradio app\n",
    "def process_query(file, query):\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "        text = pdf.pages[1].extract_text()\n",
    "    return query_rag_model(query)\n",
    "\n",
    "gr.Interface(\n",
    "    fn=process_query,\n",
    "    inputs=[\"file\", \"text\"],\n",
    "    outputs=\"text\",\n",
    "    title=\"P&L QA Bot\",\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac97b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
